import json
import time
from typing import Dict, Any, Optional
from google import genai
from google.genai import types, errors
from dotenv import load_dotenv
import os

load_dotenv()
gemini_api_key = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=gemini_api_key)

# ============================================================================
# CONFIGURATION SECTION - MODIFY THESE VALUES FOR YOUR USE CASE
# ============================================================================

# Generate reference image (Step 1)
TEST_IX = 4
GENERATE_IMAGE = True  # Set to True to generate a new reference image
IMAGE_PROMPT_FILE = "video_gen_pipeline/image_prompt.txt"
IMAGE_OUTPUT_PATH = f"data/output/generated_videos/generated_image{TEST_IX}.png"

# Generate video from reference image (Step 2)
GENERATE_VIDEO = False  # Set to False to skip video generation
VIDEO_PROMPT_FILE = "video_gen_pipeline/video_prompt.txt"
VIDEO_OUTPUT_PATH = f"data/output/generated_videos/test_video{TEST_IX}.mp4"
VIDEO_ASPECT_RATIO = "9:16"
VIDEO_DURATION_SECONDS = 8

# ============================================================================
# END CONFIGURATION SECTION
# ============================================================================


def load_transcript_from_prompt_file() -> Optional[str]:
    """Load transcript reference from the video prompt file if it contains a path."""
    # For now, return None as transcripts are embedded in the prompts generated by json_to_prompt
    # This function can be extended if we need to load transcripts separately
    return None


def generate_reference_image(prompt: str, output_path: str) -> None:
    """Generate the initial reference image using Gemini."""
    print(f"Generating reference image from prompt...")
    response = client.models.generate_content(
        model="gemini-3-pro-image-preview",
        contents=[prompt],
        config=types.GenerateContentConfig(
            image_config=types.ImageConfig(
                aspect_ratio="9:16",
            ),
        ),
    )

    for part in response.parts:
        if part.inline_data is not None:
            image = part.as_image()
            image.save(output_path)
            print(f"Reference image saved to {output_path}")


def generate_video_from_image(
    video_prompt: str,
    image_path: str,
    output_path: str,
    aspect_ratio: str = "9:16",
    duration_seconds: int = 4,
    transcript: Optional[str] = None,
) -> None:
    """Generate video from reference image using Veo-3.1."""
    print(f"Loading reference image from {image_path}...")
    image = types.Image.from_file(location=image_path)

    # Enhance prompt with transcript if available
    enhanced_prompt = video_prompt
    if transcript:
        print("Including transcript context in video generation...")
        enhanced_prompt = f"{video_prompt}\n\nContext from transcript: {transcript[:500]}"  # Limit to 500 chars

    print(f"Starting video generation...")
    try:
        operation = client.models.generate_videos(
            model="veo-3.1-generate-preview",
            prompt=enhanced_prompt,
            image=image,
            config=types.GenerateVideosConfig(
                aspect_ratio=aspect_ratio,
                duration_seconds=duration_seconds,
            ),
        )
    except errors.ClientError as e:
        print("=== ClientError from Veo ===")
        print("Status code:", e)
        print("Response JSON:", e.response_json)
        raise

    print(f"Operation started: {operation.name}")

    # Poll until video generation completes
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Check for errors
    if operation.error:
        print("Video generation FAILED:")
        print(operation.error)
        raise SystemExit(1)

    if not operation.response:
        raise RuntimeError(
            f"Video generation completed but response is None. "
            f"Operation metadata: {operation.metadata}"
        )

    if not getattr(operation.response, "generated_videos", None):
        raise RuntimeError(
            f"Video generation completed but no generated_videos found. "
            f"Operation response: {operation.response}"
        )

    # Save the generated video
    video = operation.response.generated_videos[0]
    client.files.download(file=video.video)
    video.video.save(output_path)
    print(f"Generated video saved to {output_path}")


def main():
    """Main pipeline to generate videos from templates."""
    # Read prompts from files
    with open(IMAGE_PROMPT_FILE, "r") as f:
        image_prompt = f.read().strip()
    
    with open(VIDEO_PROMPT_FILE, "r") as f:
        video_prompt = f.read().strip()
    
    # Load transcript if available
    transcript = load_transcript_from_prompt_file()
    
    if GENERATE_IMAGE:
        generate_reference_image(image_prompt, IMAGE_OUTPUT_PATH)

    if GENERATE_VIDEO:
        generate_video_from_image(
            video_prompt=video_prompt,
            image_path=IMAGE_OUTPUT_PATH,
            output_path=VIDEO_OUTPUT_PATH,
            aspect_ratio=VIDEO_ASPECT_RATIO,
            duration_seconds=VIDEO_DURATION_SECONDS,
            transcript=transcript,
        )

    print("\nPipeline completed successfully!")


if __name__ == "__main__":
    main()
